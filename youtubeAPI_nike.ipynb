{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-e9urSoupiQJ",
        "outputId": "e37ef4af-9b4d-48c9-b75b-0236334df4df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.10/dist-packages (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.10/dist-packages (1.2.1)\n",
            "Requirement already satisfied: google-auth-httplib2 in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (2.137.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib) (1.3.1)\n",
            "Requirement already satisfied: httplib2>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-httplib2) (0.22.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (2.19.2)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (4.1.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.65.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.20.3)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.25.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.32.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2>=0.19.0->google-auth-httplib2) (3.2.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "pip install google-auth google-auth-oauthlib google-auth-httplib2 google-api-python-client\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "from googleapiclient.discovery import build"
      ],
      "metadata": {
        "id": "SBVnQQV5pxsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "API_KEY = '################'"
      ],
      "metadata": {
        "id": "T7BLe-iDp1Jx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize YouTube API client\n",
        "youtube = build('youtube', 'v3', developerKey=API_KEY)\n",
        "\n",
        "def search_nike_videos(query=\"Nike shoes\", max_results=100, total_results=600):\n",
        "    videos = []\n",
        "    next_page_token = None\n",
        "    results_fetched = 0\n",
        "\n",
        "    while results_fetched < total_results:\n",
        "        # Search for videos related to Nike shoes with pagination\n",
        "        search_response = youtube.search().list(\n",
        "            q=query,\n",
        "            part='id,snippet',\n",
        "            maxResults=max_results,\n",
        "            type='video',\n",
        "            pageToken=next_page_token\n",
        "        ).execute()\n",
        "\n",
        "        for item in search_response.get('items', []):\n",
        "            video_id = item['id']['videoId']\n",
        "            video_info = get_video_details(video_id)\n",
        "            if video_info:\n",
        "                videos.append(video_info)\n",
        "                results_fetched += 1\n",
        "                if results_fetched >= total_results:\n",
        "                    break  # Stop if we have enough results\n",
        "\n",
        "        next_page_token = search_response.get('nextPageToken')\n",
        "        if not next_page_token:\n",
        "            break  # Stop if there are no more pages\n",
        "\n",
        "    return videos\n",
        "\n",
        "def get_video_details(video_id):\n",
        "    # Get details for each video\n",
        "    video_response = youtube.videos().list(\n",
        "        part='snippet,contentDetails,statistics',\n",
        "        id=video_id\n",
        "    ).execute()\n",
        "\n",
        "    for video in video_response.get('items', []):\n",
        "        # Gather video details\n",
        "        video_info = {\n",
        "            'Title': video['snippet']['title'],\n",
        "            'Upload Date': video['snippet']['publishedAt'],\n",
        "            'Views (Clicks)': video['statistics'].get('viewCount', 0),\n",
        "            'Likes': video['statistics'].get('likeCount', 0),\n",
        "            'Comments': video['statistics'].get('commentCount', 0),\n",
        "            'Description': video['snippet'].get('description', ''),\n",
        "            'Tags': ', '.join(video['snippet'].get('tags', [])),  # Join tags as a single string\n",
        "            'URL': f\"https://www.youtube.com/watch?v={video_id}\"\n",
        "        }\n",
        "        return video_info\n",
        "    return None\n",
        "\n",
        "# Fetch Nike videos with pagination\n",
        "nike_videos = search_nike_videos(total_results=600)\n",
        "\n",
        "# Filter out any None entries from nike_videos\n",
        "nike_videos = [video for video in nike_videos if video is not None]\n",
        "\n",
        "# Define CSV file path\n",
        "csv_file = \"nike_youtubeAPI_data.csv\"\n",
        "\n",
        "# Save data to CSV only if there's data to write\n",
        "if nike_videos:\n",
        "    with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "        writer = csv.DictWriter(file, fieldnames=nike_videos[0].keys())\n",
        "        writer.writeheader()\n",
        "        writer.writerows(nike_videos)\n",
        "    print(f\"Data saved to {csv_file}\")\n",
        "else:\n",
        "    print(\"No data to save.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nHC--92qI_e",
        "outputId": "07c9e080-f907-474f-a2a8-64a2d97ee187"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data saved to nike_youtubeAPI_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install textblob"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cq-WaSCPulpE",
        "outputId": "8a810aed-8d72-4160-a182-d0a01210b36c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (4.66.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Load data from the CSV file generated previously\n",
        "csv_file = \"nike_youtubeAPI_data.csv\"\n",
        "data = pd.read_csv(csv_file)\n",
        "\n",
        "# Function to analyze sentiment\n",
        "def analyze_sentiment(text):\n",
        "    blob = TextBlob(str(text))  # Convert text to string if not already\n",
        "    polarity = blob.sentiment.polarity\n",
        "    subjectivity = blob.sentiment.subjectivity\n",
        "\n",
        "    # Classify polarity\n",
        "    polarity_label = \"Positive\" if polarity > 0 else \"Negative\" if polarity < 0 else \"Neutral\"\n",
        "    # Classify subjectivity\n",
        "    subjectivity_label = \"Opinion\" if subjectivity > 0.5 else \"Fact\"\n",
        "\n",
        "    return polarity_label, subjectivity_label\n",
        "\n",
        "# Apply sentiment analysis on the Title and Description\n",
        "data['Title_Polarity'], data['Title_Subjectivity'] = zip(*data['Title'].apply(analyze_sentiment))\n",
        "data['Description_Polarity'], data['Description_Subjectivity'] = zip(*data['Description'].apply(analyze_sentiment))\n",
        "\n",
        "# Save the sentiment data to a new CSV\n",
        "output_file = \"nike_youtubeAPI_sentiment_data.csv\"\n",
        "data.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"Sentiment analysis results saved to {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uy8vVXGvuiGs",
        "outputId": "5c9c35a5-2372-4001-98ae-a9ce1a2fc9d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment analysis results saved to nike_youtubeAPI_sentiment_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Load the cleaned dataset\n",
        "file_path = \"/mnt/data/nike_youtubeAPI_sentiment_data_cleaned.csv\"\n",
        "#data = pd.read_csv(file_path)\n",
        "\n",
        "# Preprocess Data\n",
        "# Convert 'Upload Date' to datetime and extract month and day\n",
        "data['Upload Date'] = pd.to_datetime(data['Upload Date'])\n",
        "data['Upload Month'] = data['Upload Date'].dt.month\n",
        "data['Upload Day'] = data['Upload Date'].dt.day\n",
        "\n",
        "# Convert sentiment labels to numeric values (e.g., 1 for Positive, -1 for Negative)\n",
        "data['Title_Polarity_Numeric'] = data['Title_Polarity'].map({'Positive': 1, 'Negative': -1, 'Neutral': 0})\n",
        "data['Description_Polarity_Numeric'] = data['Description_Polarity'].map({'Positive': 1, 'Negative': -1, 'Neutral': 0})\n",
        "data['Title_Subjectivity_Numeric'] = data['Title_Subjectivity'].map({'Opinion': 1, 'Fact': 0})\n",
        "data['Description_Subjectivity_Numeric'] = data['Description_Subjectivity'].map({'Opinion': 1, 'Fact': 0})\n",
        "\n",
        "# Select features (independent variables) and target (dependent variable)\n",
        "X = data[['Upload Month', 'Upload Day', 'Likes', 'Comments', 'Title_Polarity_Numeric', 'Description_Polarity_Numeric']]\n",
        "y = data['Views (Clicks)']  # Target variable\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R-squared: {r2}\")\n",
        "\n",
        "# Display model coefficients\n",
        "coefficients = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Coefficient': model.coef_\n",
        "})\n",
        "print(coefficients)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8nXnpraoAOK",
        "outputId": "47cf754a-101e-4c78-f768-88fe0b6ac480"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 29179828318437.996\n",
            "R-squared: 0.6607292316762493\n",
            "                        Feature    Coefficient\n",
            "0                  Upload Month -134625.553621\n",
            "1                    Upload Day    4491.899630\n",
            "2                         Likes      24.230332\n",
            "3                      Comments     458.095327\n",
            "4        Title_Polarity_Numeric -531595.860890\n",
            "5  Description_Polarity_Numeric  254438.366009\n"
          ]
        }
      ]
    }
  ]
}